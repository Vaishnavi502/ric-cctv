{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXis06DbuPlF"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVZ80TmYs44M"
      },
      "outputs": [],
      "source": [
        "# Attempt 1 - WORKS!\n",
        "# Frame extraction\n",
        "\n",
        "# video = cv2.VideoCapture(\"/content/drive/MyDrive/IFPwork/har_detection-master/amazon_delivery2.avi\")\n",
        "\n",
        "# frames_output_folder = '/content/drive/MyDrive/IFPwork/har_detection-master/frames'\n",
        "\n",
        "# min_contour = 100 # Smaller number for smaller motions to detect\n",
        "\n",
        "# bg_subtractor = cv2.createBackgroundSubtractorKNN()\n",
        "\n",
        "# if not os.path.exists(frames_output_folder):\n",
        "#     os.makedirs(frames_output_folder)\n",
        "\n",
        "# frame_count = 0\n",
        "\n",
        "# while True:\n",
        "#     status, frame = video.read()\n",
        "#     if not status:\n",
        "#         break\n",
        "\n",
        "#     frame_count += 1\n",
        "#     # Apply background subtraction\n",
        "#     fg_mask = bg_subtractor.apply(frame)\n",
        "\n",
        "#     # fg_mask = cv2.threshold(fg_mask, 30, 255, cv2.THRESH_BINARY)[1]\n",
        "#     # fg_mask = cv2.dilate(fg_mask, None, iterations=2)\n",
        "\n",
        "#     # Store frame in folder\n",
        "#     cnts, _ = cv2.findContours(fg_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#     for contour in cnts:\n",
        "#         if cv2.contourArea(contour) > min_contour:\n",
        "#             output_path = os.path.join(frames_output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
        "#             cv2.imwrite(output_path, frame)\n",
        "\n",
        "#     # cv2.imshow(\"Motion Detection\", frame)\n",
        "\n",
        "#     key = cv2.waitKey(1)\n",
        "#     if key == ord('q'):\n",
        "#         break\n",
        "\n",
        "# video.release()\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "183MOwjSvWLS"
      },
      "outputs": [],
      "source": [
        "frame_count = 0\n",
        "added_im_count = 0 # Tracking number of images with less blur added to folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGFm1t28xirs"
      },
      "outputs": [],
      "source": [
        "# # Attempt 2\n",
        "# # Frame extraction with preprocessing images\n",
        "\n",
        "\n",
        "# video = cv2.VideoCapture(\"/content/drive/MyDrive/IFPwork/obj_detection/amazon_delivery.avi\")\n",
        "\n",
        "frames_output_folder = '/content/drive/MyDrive/IFPwork/photos_for_training_yolov3/frames3'\n",
        "\n",
        "# min_contour = 100 # Smaller number for smaller motions to detect\n",
        "\n",
        "# bg_subtractor = cv2.createBackgroundSubtractorKNN()\n",
        "\n",
        "sharpness_threshold = 500\n",
        "\n",
        "if not os.path.exists(frames_output_folder):\n",
        "    os.makedirs(frames_output_folder)\n",
        "\n",
        "# while True:\n",
        "#     status, frame = video.read()\n",
        "#     if not status:\n",
        "#         break\n",
        "#     if added_im_count >= 1000:\n",
        "#         break\n",
        "#     frame_count += 1\n",
        "#     # Apply background subtraction\n",
        "#     fg_mask = bg_subtractor.apply(frame)\n",
        "\n",
        "#     # fg_mask = cv2.threshold(fg_mask, 30, 255, cv2.THRESH_BINARY)[1]\n",
        "#     # fg_mask = cv2.dilate(fg_mask, None, iterations=2)\n",
        "\n",
        "#     # Store frame in folder\n",
        "#     cnts, _ = cv2.findContours(fg_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#     for contour in cnts:\n",
        "#         if cv2.contourArea(contour) > min_contour:\n",
        "#             # Apply preprocessing\n",
        "#             # detect blur with laplacian fn variance\n",
        "#             lap_var = cv2.Laplacian(frame, cv2.CV_64F).var()\n",
        "#             # save images that have sufficient sharpness\n",
        "#             if lap_var > sharpness_threshold:\n",
        "#                 output_path = os.path.join(frames_output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
        "#                 cv2.imwrite(output_path, frame)\n",
        "#                 added_im_count += 1\n",
        "\n",
        "#     # cv2.imshow(\"Motion Detection\", frame)\n",
        "\n",
        "#     key = cv2.waitKey(1)\n",
        "#     if key == ord('q'):\n",
        "#         break\n",
        "\n",
        "# video.release()\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjjhskXlx3fn"
      },
      "outputs": [],
      "source": [
        "# Attempt 3\n",
        "# Using \"person\" class detection in yolo\n",
        "\n",
        "net = cv2.dnn.readNet(\"/content/drive/MyDrive/IFPwork/obj_detection/yolov3-tiny.weights\", \"/content/drive/MyDrive/IFPwork/obj_detection/yolov3-tiny.cfg\")\n",
        "classes = []\n",
        "with open(\"/content/drive/MyDrive/IFPwork/obj_detection/coco.names\", \"r\") as f:\n",
        "    classes = f.read().strip().split(\"\\n\")\n",
        "# print(classes)\n",
        "video = cv2.VideoCapture(\"/content/drive/MyDrive/IFPwork/obj_detection/amazon_delivery.avi\")\n",
        "\n",
        "while True:\n",
        "    status, frame = video.read()\n",
        "    if not status:\n",
        "        break\n",
        "    if added_im_count == 1000:\n",
        "      break\n",
        "\n",
        "    frame_count += 1\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(net.getUnconnectedOutLayersNames())\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = int(detection[1])\n",
        "            confidence = scores[class_id]\n",
        "\n",
        "            if confidence > 0 and class_id == 0:  # Detect person\n",
        "                # Apply preprocessing\n",
        "                # detect blur with laplacian fn variance\n",
        "                lap_var = cv2.Laplacian(frame, cv2.CV_64F).var()\n",
        "                # save images that have sufficient sharpness\n",
        "                if lap_var > sharpness_threshold:\n",
        "                    output_path = os.path.join(frames_output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
        "                    cv2.imwrite(output_path, frame)\n",
        "                    added_im_count += 1\n",
        "    key = cv2.waitKey(1)\n",
        "    if key == ord('q'):\n",
        "        break\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}